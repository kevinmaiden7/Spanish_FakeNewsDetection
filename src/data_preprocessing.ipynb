{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length_text(df):\n",
    "    max_length = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        length = np.size(word_tokenize(df.at[i, 'text']))\n",
    "        if length > max_length: max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_length_histogram(df):\n",
    "    lengths = []\n",
    "    for i in range(df.shape[0]):\n",
    "        length = np.size(word_tokenize(df.at[i, 'text']))\n",
    "        lengths.append(length)\n",
    "    \n",
    "    plt.hist(lengths, bins = 20)\n",
    "    plt.show()\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization(data):\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "    data['text'] = data['text'].apply((lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data, language, get_tokenize):\n",
    "    stopwords = nltk.corpus.stopwords.words(language)\n",
    "    if get_tokenize:\n",
    "        for i in range(data.shape[0]):\n",
    "            data.at[i, 'text'] = [word for word in nltk.word_tokenize(data.at[i, 'text']) if word not in stopwords]\n",
    "    else:\n",
    "        for i in range(data.shape[0]):\n",
    "            data.at[i, 'text'] = [word for word in nltk.word_tokenize(data.at[i, 'text']) if word not in stopwords]\n",
    "            data.at[i, 'text'] = ' '.join(data.at[i, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(data, language):\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for i in range(data.shape[0]):\n",
    "         data.at[i, 'text'] = (' '.join([stemmer.stem(word) for word in data.at[i, 'text'].split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_matrix representation | BoW and Tf-idf for Classic ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data, representation, vocabulary_length, stemming, remove_stopwords, language):\n",
    "\n",
    "    df = data.copy(deep = True)\n",
    "    \n",
    "    text_normalization(df) # Text normalization\n",
    "    \n",
    "    # Stop_words\n",
    "    if remove_stopwords:\n",
    "        remove_stop_words(df, language, False)\n",
    "    \n",
    "    # Stemming\n",
    "    if stemming:\n",
    "        apply_stemming(df, language)\n",
    "    \n",
    "    # Word representation\n",
    "    if representation == 'BoW':\n",
    "        count_vectorizer = CountVectorizer(max_df = 0.9, max_features = vocabulary_length, min_df = 0)\n",
    "        #count_vectorizer = CountVectorizer(max_features = vocabulary_length)\n",
    "        matrix = count_vectorizer.fit_transform(df.text)\n",
    "        \n",
    "    elif representation == 'tf-idf':\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_df = 0.9, max_features = vocabulary_length, min_df = 0, use_idf = True)\n",
    "        #tfidf_vectorizer = TfidfVectorizer(max_features = vocabulary_length, use_idf=True)\n",
    "        matrix = tfidf_vectorizer.fit_transform(df.text)\n",
    "    \n",
    "    return matrix, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing for RNN - LSTM; CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(data, stemming, remove_stopwords, vocabulary_length, max_length_sequence, language):\n",
    "    \n",
    "    df = data.copy(deep = True)\n",
    "    \n",
    "    text_normalization(df) # Text normalization\n",
    "    \n",
    "    # Stemming\n",
    "    if stemming:\n",
    "        apply_stemming(df, language)\n",
    "    \n",
    "    # Stop_words\n",
    "    if remove_stopwords:\n",
    "        remove_stop_words(df, language, True)\n",
    "        \n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(num_words = vocabulary_length)\n",
    "    tokenizer.fit_on_texts(df.text)\n",
    "    X = tokenizer.texts_to_sequences(df.text)\n",
    "    \n",
    "    # Padding\n",
    "    X = pad_sequences(X, maxlen = max_length_sequence, padding = 'post', truncating = 'post')\n",
    "    \n",
    "    return X, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_share_tokenizer(data_1, data_2, stemming, remove_stopwords, vocabulary_length, max_length_sequence, language):\n",
    "    \n",
    "    df1 = data_1.copy(deep = True)\n",
    "    df2 = data_2.copy(deep = True)\n",
    "    \n",
    "    text_normalization(df1) # Text normalization\n",
    "    text_normalization(df2)\n",
    "    \n",
    "    # Stemming\n",
    "    if stemming:\n",
    "        apply_stemming(df1, language)\n",
    "        apply_stemming(df2, language)\n",
    "    \n",
    "    # Stop_words\n",
    "    if remove_stopwords:\n",
    "        remove_stop_words(df1, language, True)\n",
    "        remove_stop_words(df2, language, True)\n",
    "        \n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(num_words = vocabulary_length)\n",
    "    tokenizer.fit_on_texts(df1.text)\n",
    "    X_1 = tokenizer.texts_to_sequences(df1.text)\n",
    "    X_2 = tokenizer.texts_to_sequences(df2.text)\n",
    "    \n",
    "    # Padding\n",
    "    X_1 = pad_sequences(X_1, maxlen = max_length_sequence, padding = 'post', truncating = 'post')\n",
    "    X_2 = pad_sequences(X_2, maxlen = max_length_sequence, padding = 'post', truncating = 'post')\n",
    "    \n",
    "    return X_1, X_2, df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spanish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La palabra \"haiga\", aceptada por la RAE La Rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alerta: pretenden aprobar libros escolares con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Recuperamos la historia de Aleixandra, la jove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Reproches, tensión y sinceridad: la comida en ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>Rusia cita al embajador español por unas decla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>Saeed Malekpour fue detenido en 2008, cuando v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...      1\n",
       "1     La palabra \"haiga\", aceptada por la RAE La Rea...      1\n",
       "2     YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...      1\n",
       "3     UNAM capacitará a maestros para aprobar prueba...      0\n",
       "4     Alerta: pretenden aprobar libros escolares con...      1\n",
       "...                                                 ...    ...\n",
       "2566  Recuperamos la historia de Aleixandra, la jove...      0\n",
       "2567  Reproches, tensión y sinceridad: la comida en ...      0\n",
       "2568  RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...      0\n",
       "2569  Rusia cita al embajador español por unas decla...      0\n",
       "2570  Saeed Malekpour fue detenido en 2008, cuando v...      0\n",
       "\n",
       "[2571 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/Merged/spanish_dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2865"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.06\n"
     ]
    }
   ],
   "source": [
    "lengths = sequence_length_histogram(dataset)\n",
    "print(round(np.mean(lengths), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONARIO DEL IDIOMA ESPAÑOL COMO DEFINICIÓN DE \"MUJER PROBLEMÁTICA\"\n",
      "España.- El presidente de la Real Academia Española (RAE), Darío Villanueva, informó en conferencia de prensa que a partir del próximo mes se incluirá el término \"Lady\" como una nueva palabra en el diccionario del idioma español.\n",
      "Darío señaló que \"Lady\" servirá para definir a una \"mujer problemática\" o a una \"mujer que causa problemas\", y mencionó que esta palabra será una de las pocas que también se utilizan en el idioma inglés pero que en castellano tiene un significado diferente:\n",
      "\"Son contadas las palabras del idioma inglés que se utilizan en el español pero que tienen otro significado. Con la globalización las personas han comenzado a adoptar términos anglosajones pero los utilizan con su significado real, sin embargo en este caso la expresión Lady no significará lo mismo que en su idioma original (\"dama\" en inglés) sino que se usará para definir a una mujer que es problemática o acostumbra causar problemas y alborotos.\n",
      "La gente podrá decirle Lady a una fémina que cause algún escándalo, sea agresiva o provoque algún tipo de problema. El término dejara de considerarse una palabra exclusiva del idioma inglés ya que tras se incluida en el diccionario de la lengua española también pasara ser una palabra oficial del castellano, pero con un significado distinto\", confesó.\n",
      "Villanueva presentó a los medios la definición oficial que aparecerá en los diccionarios, señalando que será la siguiente:\n",
      "-Lady\n",
      "Del anglosajón Ænglisc, part. de Difficilis 'problematica', ferox 'agresiva'\n",
      "*NUMBER*.- adj. f. Mujer excesivamente problemática\n",
      "*NUMBER*.- adj. f. Mujer que causa problemas o alborotos\n",
      "*NUMBER*.- adj. f. Mujer que tiende a causar conflictos, es agresiva\n",
      "Te puede interesar Cholas descubren que las Donitas Bimbo también se pueden comer y no solo sirven para maquillarse\n",
      "*NUMBER*.- adj. f. Mujer que se guía por sus instintos animales, que no le importa crear conflictos\n",
      "El presidente señaló que fue uno de los miembros mexicanos de la RAE quien propuso incluir la palabra, y tras meses de análisis finamente fue aceptada por el comité:\n",
      "\"Es una término que tuvo su origen en México pero se usará en todos los países de habla hispana. Los videos de las Lady´s que han circulado nos sirvieron para crear una perfecta definición, la cual servirá para resumir y definir a una hembra problemática\", dijo\n",
      "Por último, Darío reveló que también ya se encuentran analizando la idea de incluir el término Lord en el diccionario, que sería el equivalente a la definición masculina de Lady.\n"
     ]
    }
   ],
   "source": [
    "print(dataset.at[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rae', 'incluirá', 'palabra', 'lady', 'diccionario', 'idioma', 'español', 'definición', 'mujer', 'problemática', 'españa', 'presidente', 'real', 'academia', 'española', 'rae', 'darío', 'villanueva', 'informó', 'conferencia', 'prensa', 'partir', 'próximo', 'mes', 'incluirá', 'término', 'lady', 'nueva', 'palabra', 'diccionario', 'idioma', 'español', 'darío', 'señaló', 'lady', 'servirá', 'definir', 'mujer', 'problemática', 'mujer', 'causa', 'problemas', 'mencionó', 'palabra', 'pocas', 'utilizan', 'idioma', 'inglés', 'castellano', 'significado', 'diferente', 'contadas', 'palabras', 'idioma', 'inglés', 'utilizan', 'español', 'significado', 'globalización', 'personas', 'comenzado', 'adoptar', 'términos', 'anglosajones', 'utilizan', 'significado', 'real', 'embargo', 'caso', 'expresión', 'lady', 'significará', 'mismo', 'idioma', 'original', 'dama', 'inglés', 'sino', 'usará', 'definir', 'mujer', 'problemática', 'acostumbra', 'causar', 'problemas', 'alborotos', 'gente', 'podrá', 'decirle', 'lady', 'fémina', 'cause', 'algún', 'escándalo', 'agresiva', 'provoque', 'algún', 'tipo', 'problema', 'término', 'dejara', 'considerarse', 'palabra', 'exclusiva', 'idioma', 'inglés', 'tras', 'incluida', 'diccionario', 'lengua', 'española', 'pasara', 'ser', 'palabra', 'oficial', 'castellano', 'significado', 'distinto', 'confesó', 'villanueva', 'presentó', 'medios', 'definición', 'oficial', 'aparecerá', 'diccionarios', 'señalando', 'siguiente', 'lady', 'anglosajón', 'ænglisc', 'part', 'difficilis', 'problematica', 'ferox', 'agresiva', 'number', 'adj', 'f', 'mujer', 'excesivamente', 'problemática', 'number', 'adj', 'f', 'mujer', 'causa', 'problemas', 'alborotos', 'number', 'adj', 'f', 'mujer', 'tiende', 'causar', 'conflictos', 'agresiva', 'puede', 'interesar', 'cholas', 'descubren', 'donitas', 'bimbo', 'pueden', 'comer', 'solo', 'sirven', 'maquillarse', 'number', 'adj', 'f', 'mujer', 'guía', 'instintos', 'animales', 'importa', 'crear', 'conflictos', 'presidente', 'señaló', 'miembros', 'mexicanos', 'rae', 'propuso', 'incluir', 'palabra', 'tras', 'meses', 'análisis', 'finamente', 'aceptada', 'comité', 'término', 'origen', 'méxico', 'usará', 'países', 'habla', 'hispana', 'videos', 'lady´s', 'circulado', 'sirvieron', 'crear', 'perfecta', 'definición', 'servirá', 'resumir', 'definir', 'hembra', 'problemática', 'dijo', 'último', 'darío', 'reveló', 'encuentran', 'analizando', 'idea', 'incluir', 'término', 'lord', 'diccionario', 'equivalente', 'definición', 'masculina', 'lady']\n",
      "(2571, 2)\n"
     ]
    }
   ],
   "source": [
    "X, df = get_input(dataset, False, True, 10000, 500, language = 'spanish')\n",
    "# X, df = get_input(dataset, True, True, 40000, 2900, language = 'spanish')\n",
    "print(df.at[0, 'text'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2571, 500)\n",
      "2571\n",
      "[1328 3124  729 2909 2261 1639  232 4706   91 5246   54    9  268  975\n",
      "  352 1328 4300 5247  359  330  176  138  166  122 3124 1786 2909   71\n",
      "  729 2261 1639  232 4300  123 2909 3125 1961   91 5246   91  548  326\n",
      "  303  729 1484 1962 1639  645 5942 3126 1485  463 1639  645 1962  232\n",
      " 3126 9847   17 2544 3939 1038 1962 3126  268   68   34 1329 2909   56\n",
      " 1639 2262  481  645  100 4707 1961   91 5246 9848 2411  326   63  264\n",
      " 3649 2909 9849 9850  464  838 4708 8041  464  170  315 1786 4301 9851\n",
      "  729 1559 1639  645   26 4302 2261 2711  352 6792    5  729  265 5942\n",
      " 3126 4303 1169 5247  769  104 4706  265 4304  887  534 2909 4708    1\n",
      " 8042 2545   91 8043 5246    1 8042 2545   91  548  326    1 8042 2545\n",
      "   91 5943 2411 2263 4708   27 9852 2712 9853  124 1285   31 5248    1\n",
      " 8042 2545   91 5249  646 1170  861 2263    9  123  564   80 1328 2713\n",
      " 1787  729   26   97 1127 6793 1330 1786  574    2 4707  167  713 6794\n",
      " 1039  861 4709 4706 3125 1961 9854 5246   11  215 4300  492  730 3940\n",
      "  248 1787 1786 9855 2261 2042 4706 9856 2909    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0] 500\n",
      "[1328 3124  729 2909 2261 1639  232 4706   91 5246   54    9  268  975\n",
      "  352 1328 4300 5247  359  330  176  138  166  122 3124 1786 2909   71\n",
      "  729 2261 1639  232 4300  123 2909 3125 1961   91 5246   91  548  326\n",
      "  303  729 1484 1962 1639  645 5942 3126 1485  463 1639  645 1962  232\n",
      " 3126 9847   17 2544 3939 1038 1962 3126  268   68   34 1329 2909   56\n",
      " 1639 2262  481  645  100 4707 1961   91 5246 9848 2411  326   63  264\n",
      " 3649 2909 9849 9850  464  838 4708 8041  464  170  315 1786 4301 9851\n",
      "  729 1559 1639  645   26 4302 2261 2711  352 6792    5  729  265 5942\n",
      " 3126 4303 1169 5247  769  104 4706  265 4304  887  534 2909 4708    1\n",
      " 8042 2545   91 8043 5246    1 8042 2545   91  548  326    1 8042 2545\n",
      "   91 5943 2411 2263 4708   27 9852 2712 9853  124 1285   31 5248    1\n",
      " 8042 2545   91 5249  646 1170  861 2263    9  123  564   80 1328 2713\n",
      " 1787  729   26   97 1127 6793 1330 1786  574    2 4707  167  713 6794\n",
      " 1039  861 4709 4706 3125 1961 9854 5246   11  215 4300  492  730 3940\n",
      "  248 1787 1786 9855 2261 2042 4706 9856 2909    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(X))\n",
    "print(X[0], len(X[0]))\n",
    "print(X[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 729 6795 6793 1328  268  975 2711 1328 3379  223 6795 5944   40   17\n",
      " 9857 1128 9858 4710   53   42  279   81 8044 2711 9859   58  400  285\n",
      "    8 1012  437 1328 3380  152   20 3381 1286 1099  975 2711   26 8045\n",
      " 5944 1245   21 2714   17  493  493 6796 1963 1716 5945 5250  335 5946\n",
      " 4305   85 6795  190 2910 5946 4305 6795 8046  463 3379 1328 5251  794\n",
      "  152  289 5947  770  401  401  224  729  534  362    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0] 500\n"
     ]
    }
   ],
   "source": [
    "print(X[1], len(X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51232</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "51228  The State Department told the Republican Natio...      0\n",
       "51229  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1\n",
       "51230   Anti-Trump Protesters Are Tools of the Oligar...      1\n",
       "51231  ADDIS ABABA, Ethiopia —President Obama convene...      0\n",
       "51232  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0\n",
       "\n",
       "[51233 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv('../data/Merged/english_dataset.csv')\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_text(english_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508.65\n"
     ]
    }
   ],
   "source": [
    "lengths = sequence_length_histogram(english_dataset)\n",
    "print(round(np.mean(lengths), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n"
     ]
    }
   ],
   "source": [
    "print(english_dataset.at[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['donald', 'trump', 'wish', 'americans', 'happy', 'new', 'year', 'leave', 'instead', 'give', 'shout', 'enemies', 'haters', 'dishonest', 'fake', 'news', 'media', 'former', 'reality', 'show', 'star', 'one', 'job', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', 'president', 'angry', 'pants', 'tweeted', '2018', 'great', 'year', 'america', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', '2018', 'great', 'year', 'america', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', '31', '2017trump', 'tweet', 'went', 'welll', 'expectwhat', 'kind', 'president', 'sends', 'new', 'year', 'greeting', 'like', 'despicable', 'petty', 'infantile', 'gibberish', 'trump', 'lack', 'decency', 'even', 'allow', 'rise', 'gutter', 'long', 'enough', 'wish', 'american', 'citizens', 'happy', 'new', 'year', 'bishop', 'talbert', 'swan', 'talbertswan', 'december', '31', '2017no', 'one', 'likes', 'calvin', 'calvinstowell', 'december', '31', '2017your', 'impeachment', 'would', 'make', '2018', 'great', 'year', 'america', 'also', 'accept', 'regaining', 'control', 'congress', 'miranda', 'yaver', 'mirandayaver', 'december', '31', '2017do', 'hear', 'talk', 'include', 'many', 'people', 'hate', 'wonder', 'hate', 'alan', 'sandoval', 'alansandoval13', 'december', '31', '2017who', 'uses', 'word', 'haters', 'new', 'years', 'wish', 'marlene', 'marlene399', 'december', '31', '2017you', 'say', 'happy', 'new', 'year', 'koren', 'pollitt', 'korencarpenter', 'december', '31', '2017here', 'trump', 'new', 'year', 'eve', 'tweet', '2016happy', 'new', 'year', 'including', 'many', 'enemies', 'fought', 'lost', 'badly', 'know', 'love', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', '31', '2016this', 'nothing', 'new', 'trump', 'yearstrump', 'directed', 'messages', 'enemies', 'haters', 'new', 'year', 'easter', 'thanksgiving', 'anniversary', '911', 'pictwittercom4fpae2kypa', 'daniel', 'dale', 'ddale8', 'december', '31', '2017trump', 'holiday', 'tweets', 'clearly', 'presidentialhow', 'long', 'work', 'hallmark', 'becoming', 'president', 'steven', 'goodine', 'sgoodine', 'december', '31', '2017he', 'always', 'like', 'difference', 'last', 'years', 'filter', 'breaking', 'roy', 'schulze', 'thbthttt', 'december', '31', '2017who', 'apart', 'teenager', 'uses', 'term', 'haters', 'wendy', 'wendywhistles', 'december', '31', '2017he', 'fucking', '5', 'year', 'old', 'knows', 'rainyday80', 'december', '31', '2017so', 'people', 'voted', 'hole', 'thinking', 'would', 'change', 'got', 'power', 'wrong', '70yearold', 'men', 'change', 'year', 'olderphoto', 'andrew', 'burtongetty', 'images']\n",
      "(51233, 2)\n"
     ]
    }
   ],
   "source": [
    "X, df = get_input(english_dataset, False, True, 10000, 1500, language = 'english')\n",
    "print(df.at[0, 'text'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51233, 1500)\n",
      "51233\n",
      "[  19    2 2225 ...    0    0    0] 1500\n",
      "[  19    2 2225 ...    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(X))\n",
    "print(X[0], len(X[0]))\n",
    "print(X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Original English Dataset with Translated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAE WILL INCLUDE THE WORD \"LADY\" IN THE SPANIS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The word \"haiga\", accepted by the RAE The Roya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YORDI ROSADO WILL WRITE AND DESIGN THE NEW SEP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNAM will train teachers to pass the Pisa test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alert: they intend to approve school books wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>We recover the story of Aleixandra, the 21-yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Reproaches, tension and sincerity: the meal in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>Russia quotes the Spanish ambassador for some ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>Saeed Malekpour was arrested in 2008, while vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     RAE WILL INCLUDE THE WORD \"LADY\" IN THE SPANIS...      1\n",
       "1     The word \"haiga\", accepted by the RAE The Roya...      1\n",
       "2     YORDI ROSADO WILL WRITE AND DESIGN THE NEW SEP...      1\n",
       "3     UNAM will train teachers to pass the Pisa test...      0\n",
       "4     Alert: they intend to approve school books wit...      1\n",
       "...                                                 ...    ...\n",
       "2566  We recover the story of Aleixandra, the 21-yea...      0\n",
       "2567  Reproaches, tension and sincerity: the meal in...      0\n",
       "2568  RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos and ...      0\n",
       "2569  Russia quotes the Spanish ambassador for some ...      0\n",
       "2570  Saeed Malekpour was arrested in 2008, while vi...      0\n",
       "\n",
       "[2571 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_dataset = pd.read_csv('../data/Merged/spanish_t_dataset.csv')\n",
    "translated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = english_dataset.copy(deep = True)\n",
    "df2 = translated_dataset.copy(deep = True)\n",
    "\n",
    "language = 'english'\n",
    "vocabulary_length = 10000\n",
    "\n",
    "text_normalization(df1) \n",
    "text_normalization(df2) \n",
    "\n",
    "remove_stop_words(df1, language, True)\n",
    "remove_stop_words(df2, language, True)\n",
    "\n",
    "tokenizer_df1 = Tokenizer(num_words = vocabulary_length)\n",
    "tokenizer_df1.fit_on_texts(df1.text)\n",
    "\n",
    "tokenizer_df2 = Tokenizer(num_words = vocabulary_length)\n",
    "tokenizer_df2.fit_on_texts(df2.text)\n",
    "\n",
    "#tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_df2.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262793 26125\n"
     ]
    }
   ],
   "source": [
    "vocab_list_df1 = list(tokenizer_df1.word_index.keys())\n",
    "vocab_list_df2 = list(tokenizer_df2.word_index.keys())\n",
    "print(len(vocab_list_df1), len(vocab_list_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', 'trump', '’', '“', '”', 'us', 'would', 'president', 'people', 'one'] ['number', 'one', 'de', 'mexico', 'said', 'people', 'would', 'also', 'years', 'la']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_list_df1[:10] ,vocab_list_df2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account all the words found by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18786 71.908\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for word in vocab_list_df2:\n",
    "    if word in vocab_list_df1: count += 1\n",
    "print(count, round((count*100)/len(vocab_list_df2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the 10000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6002 60.02\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "vocab_list_df1_10k = vocab_list_df1[:vocabulary_length]\n",
    "vocab_list_df2_10k = vocab_list_df2[:vocabulary_length]\n",
    "\n",
    "for word in vocab_list_df2_10k:\n",
    "    if word in vocab_list_df1_10k: count += 1\n",
    "print(count, round((count*100)/len(vocab_list_df2_10k), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
