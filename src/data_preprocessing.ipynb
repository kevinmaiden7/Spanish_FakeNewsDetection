{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length_text(df):\n",
    "    max_length = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        length = np.size(word_tokenize(df.at[i, 'text']))\n",
    "        if length > max_length: max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization(data):\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "    data['text'] = data['text'].apply((lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data, language):\n",
    "    stopwords = nltk.corpus.stopwords.words(language)\n",
    "    for i in range(data.shape[0]):\n",
    "        data.at[i, 'text'] = [word for word in nltk.word_tokenize(data.at[i, 'text']) if word not in stopwords]\n",
    "        data.at[i, 'text'] = ' '.join(data.at[i, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(data, language):\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for i in range(data.shape[0]):\n",
    "         data.at[i, 'text'] = (' '.join([stemmer.stem(word) for word in data.at[i, 'text'].split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data, representation, vocabulary_length, stemming, remove_stopwords, language):\n",
    "\n",
    "    df = data.copy(deep = True)\n",
    "    \n",
    "    text_normalization(df) # Text normalization\n",
    "    \n",
    "    # Stop_words\n",
    "    if remove_stopwords:\n",
    "        remove_stop_words(df, language)\n",
    "    \n",
    "    # Stemming\n",
    "    if stemming:\n",
    "        apply_stemming(df, language)\n",
    "    \n",
    "    # Word representation\n",
    "    if representation == 'BoW':\n",
    "        #count_vectorizer = CountVectorizer(max_df = 0.9, max_features = vocabulary_length, min_df = 0.1)\n",
    "        count_vectorizer = CountVectorizer(max_features = vocabulary_length)\n",
    "        matrix = count_vectorizer.fit_transform(df.text)\n",
    "        \n",
    "    elif representation == 'tf-idf':\n",
    "        #tfidf_vectorizer = TfidfVectorizer(max_df = 0.9, max_features = vocabulary_length, min_df = 0.1, use_idf=True)\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_features = vocabulary_length, use_idf=True)\n",
    "        matrix = tfidf_vectorizer.fit_transform(df.text)\n",
    "    \n",
    "    return matrix, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>La palabra \"haiga\", aceptada por la RAE La Rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Alerta: pretenden aprobar libros escolares con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2566</td>\n",
       "      <td>Recuperamos la historia de Aleixandra, la jove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2567</td>\n",
       "      <td>Reproches, tensión y sinceridad: la comida en ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2568</td>\n",
       "      <td>RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2569</td>\n",
       "      <td>Rusia cita al embajador español por unas decla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>Saeed Malekpour fue detenido en 2008, cuando v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...      1\n",
       "1     La palabra \"haiga\", aceptada por la RAE La Rea...      1\n",
       "2     YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...      1\n",
       "3     UNAM capacitará a maestros para aprobar prueba...      0\n",
       "4     Alerta: pretenden aprobar libros escolares con...      1\n",
       "...                                                 ...    ...\n",
       "2566  Recuperamos la historia de Aleixandra, la jove...      0\n",
       "2567  Reproches, tensión y sinceridad: la comida en ...      0\n",
       "2568  RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...      0\n",
       "2569  Rusia cita al embajador español por unas decla...      0\n",
       "2570  Saeed Malekpour fue detenido en 2008, cuando v...      0\n",
       "\n",
       "[2571 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/Merged/spanish_dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONARIO DEL IDIOMA ESPAÑOL COMO DEFINICIÓN DE \"MUJER PROBLEMÁTICA\"\n",
      "España.- El presidente de la Real Academia Española (RAE), Darío Villanueva, informó en conferencia de prensa que a partir del próximo mes se incluirá el término \"Lady\" como una nueva palabra en el diccionario del idioma español.\n",
      "Darío señaló que \"Lady\" servirá para definir a una \"mujer problemática\" o a una \"mujer que causa problemas\", y mencionó que esta palabra será una de las pocas que también se utilizan en el idioma inglés pero que en castellano tiene un significado diferente:\n",
      "\"Son contadas las palabras del idioma inglés que se utilizan en el español pero que tienen otro significado. Con la globalización las personas han comenzado a adoptar términos anglosajones pero los utilizan con su significado real, sin embargo en este caso la expresión Lady no significará lo mismo que en su idioma original (\"dama\" en inglés) sino que se usará para definir a una mujer que es problemática o acostumbra causar problemas y alborotos.\n",
      "La gente podrá decirle Lady a una fémina que cause algún escándalo, sea agresiva o provoque algún tipo de problema. El término dejara de considerarse una palabra exclusiva del idioma inglés ya que tras se incluida en el diccionario de la lengua española también pasara ser una palabra oficial del castellano, pero con un significado distinto\", confesó.\n",
      "Villanueva presentó a los medios la definición oficial que aparecerá en los diccionarios, señalando que será la siguiente:\n",
      "-Lady\n",
      "Del anglosajón Ænglisc, part. de Difficilis 'problematica', ferox 'agresiva'\n",
      "*NUMBER*.- adj. f. Mujer excesivamente problemática\n",
      "*NUMBER*.- adj. f. Mujer que causa problemas o alborotos\n",
      "*NUMBER*.- adj. f. Mujer que tiende a causar conflictos, es agresiva\n",
      "Te puede interesar Cholas descubren que las Donitas Bimbo también se pueden comer y no solo sirven para maquillarse\n",
      "*NUMBER*.- adj. f. Mujer que se guía por sus instintos animales, que no le importa crear conflictos\n",
      "El presidente señaló que fue uno de los miembros mexicanos de la RAE quien propuso incluir la palabra, y tras meses de análisis finamente fue aceptada por el comité:\n",
      "\"Es una término que tuvo su origen en México pero se usará en todos los países de habla hispana. Los videos de las Lady´s que han circulado nos sirvieron para crear una perfecta definición, la cual servirá para resumir y definir a una hembra problemática\", dijo\n",
      "Por último, Darío reveló que también ya se encuentran analizando la idea de incluir el término Lord en el diccionario, que sería el equivalente a la definición masculina de Lady.\n"
     ]
    }
   ],
   "source": [
    "print(dataset.at[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rae inclu palabr lady diccionari idiom español definicion muj problemat españ president real academi español rae dari villanuev inform conferent prens part proxim mes inclu termin lady nuev palabr diccionari idiom español dari señal lady serv defin muj problemat muj caus problem mencion palabr poc utiliz idiom ingles castellan signific diferent cont palabr idiom ingles utiliz español signific globaliz person comenz adopt termin anglosajon utiliz signific real embarg cas expresion lady signific mism idiom original dam ingles sin usar defin muj problemat acostumbr caus problem alborot gent podr dec lady femin caus algun escandal agres provoqu algun tip problem termin dej consider palabr exclus idiom ingles tras inclu diccionari lengu español pas ser palabr oficial castellan signific distint confes villanuev present medi definicion oficial aparec diccionari señal siguient lady anglosajon ænglisc part difficilis problemat ferox agres numb adj f muj exces problemat numb adj f muj caus problem alborot numb adj f muj tiend caus conflict agres pued interes chol descubr donit bimb pued com sol sirv maquill numb adj f muj gui instint animal import cre conflict president señal miembr mexican rae propus inclu palabr tras mes analisis fin acept comit termin orig mexic usar pais habl hispan vide lady´s circul sirv cre perfect definicion serv resum defin hembr problemat dij ultim dari revel encuentr analiz ide inclu termin lord diccionari equivalent definicion masculin lady\n",
      "(2571, 52)\n",
      "[[0.         0.         0.         ... 0.14697857 0.         0.        ]\n",
      " [0.         0.         0.29498395 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.14726023]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.6268063  0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "matrix, df = get_matrix(data = dataset, representation = 'tf-idf', vocabulary_length = 50000, stemming = True, remove_stopwords = True, language = 'spanish')\n",
    "print(df.at[0, 'text'])\n",
    "print(matrix.shape)\n",
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 49)\t0.14697856906977055\n",
      "  (0, 10)\t0.14009449219471973\n",
      "  (0, 28)\t0.12950632140890075\n",
      "  (0, 22)\t0.12470913139466505\n",
      "  (0, 23)\t0.14714405009170628\n",
      "  (0, 46)\t0.12292365957582499\n",
      "  (0, 38)\t0.2554840835555722\n",
      "  (0, 27)\t0.4097822095419885\n",
      "  (0, 19)\t0.13855926345420705\n",
      "  (0, 41)\t0.12083262348490409\n",
      "  (0, 30)\t0.11641040938316255\n",
      "  (0, 48)\t0.28757915280751595\n",
      "  (0, 8)\t0.1421265973698731\n",
      "  (0, 33)\t0.14952640450270696\n",
      "  (0, 24)\t0.14009449219471973\n",
      "  (0, 5)\t0.1298448906057435\n",
      "  (0, 31)\t0.1376086415204816\n",
      "  (0, 42)\t0.4360682801209263\n",
      "  (0, 26)\t0.12491191963451485\n",
      "  (0, 21)\t0.29264521670536775\n",
      "  (0, 29)\t0.22232659072879243\n",
      "  (0, 15)\t0.138696705284583\n",
      "  (0, 35)\t0.2615205531005691\n"
     ]
    }
   ],
   "source": [
    "print(matrix[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
