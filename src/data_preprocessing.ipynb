{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>La palabra \"haiga\", aceptada por la RAE La Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Alerta: pretenden aprobar libros escolares con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2271</td>\n",
       "      <td>0</td>\n",
       "      <td>Recuperamos la historia de Aleixandra, la jove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2272</td>\n",
       "      <td>0</td>\n",
       "      <td>Reproches, tensión y sinceridad: la comida en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2274</td>\n",
       "      <td>0</td>\n",
       "      <td>Rusia cita al embajador español por unas decla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>0</td>\n",
       "      <td>Saeed Malekpour fue detenido en 2008, cuando v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...\n",
       "1         0  La palabra \"haiga\", aceptada por la RAE La Rea...\n",
       "2         0  YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...\n",
       "3         1  UNAM capacitará a maestros para aprobar prueba...\n",
       "4         0  Alerta: pretenden aprobar libros escolares con...\n",
       "...     ...                                                ...\n",
       "2271      0  Recuperamos la historia de Aleixandra, la jove...\n",
       "2272      0  Reproches, tensión y sinceridad: la comida en ...\n",
       "2273      0  RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos y Vo...\n",
       "2274      0  Rusia cita al embajador español por unas decla...\n",
       "2275      0  Saeed Malekpour fue detenido en 2008, cuando v...\n",
       "\n",
       "[2276 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/Merged/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MAESTRA DE *NUMBER* AÑOS QUE TUVO RELACIONES C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oxford lanza sus propios exámenes de certifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>La RAE estudia incluir «machirulo» en el Dicci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Malala Yousafzai anuncia que estudiará en Oxfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nombran a Ricardo Arjona nuevo miembro de la R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>Meryl Streep disfrutó unos premios Oscar tan m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>Ricardo Arjona lanza una serie documental por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>Raúl Araiza sorprende a Andrea Legarreta con b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>Adal Ramones protagonizará el remake de El Cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        0  MAESTRA DE *NUMBER* AÑOS QUE TUVO RELACIONES C...\n",
       "1        1  Oxford lanza sus propios exámenes de certifica...\n",
       "2        1  La RAE estudia incluir «machirulo» en el Dicci...\n",
       "3        1  Malala Yousafzai anuncia que estudiará en Oxfo...\n",
       "4        0  Nombran a Ricardo Arjona nuevo miembro de la R...\n",
       "..     ...                                                ...\n",
       "290      1  Meryl Streep disfrutó unos premios Oscar tan m...\n",
       "291      0  EL PLAGIO DE LANA DEL REY A RADIOHEAD FUE ACOR...\n",
       "292      1  Ricardo Arjona lanza una serie documental por ...\n",
       "293      1  Raúl Araiza sorprende a Andrea Legarreta con b...\n",
       "294      0  Adal Ramones protagonizará el remake de El Cha...\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/Merged/test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(df):\n",
    "    max_length = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        length = np.size(word_tokenize(df.at[i, 'text']))\n",
    "        if length > max_length: max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    for i in range(df.shape[0]):\n",
    "        df.at[i, 'text'] = [word.lower() for word in tokenizer.tokenize(df.at[i, 'text']) if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_remove_punctuation(data):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    for i in range(df.shape[0]):\n",
    "        df.at[i, 'text'] = [word.lower() for word in tokenizer.tokenize(df.at[i, 'text'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data, representation, vocabulary_length, stop_words_flag):\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    for i in range(df.shape[0]):\n",
    "         df.at[i, 'text'] = (\" \".join([stemmer.stem(word) for word in df.at[i, 'text'].split()]))\n",
    "    \n",
    "    print(data.at[0, 'text']) #\n",
    "    \n",
    "    # Stop_words\n",
    "    if stop_words_flag:\n",
    "        remove_stop_words(data)\n",
    "    else:\n",
    "        only_remove_punctuation(data)\n",
    "        \n",
    "    print(data.at[0, 'text']) #\n",
    "    \n",
    "    # Word representation\n",
    "    if representation == 'BoW':\n",
    "        for i in range(df.shape[0]):\n",
    "            count_vectorizer = CountVectorizer(max_features = vocabulary_length)\n",
    "            matrix = count_vectorizer.fit_transform(data.at[i, 'text']) #fit the vectorizer to synopses\n",
    "            data.at[i, 'text'] = matrix.toarray()\n",
    "        \n",
    "    elif representation == 'tf-idf':\n",
    "        for i in range(df.shape[0]):\n",
    "            tfidf_vectorizer = TfidfVectorizer(max_features = vocabulary_length, use_idf=True)\n",
    "            matrix = tfidf_vectorizer.fit_transform(data.at[i, 'text']) #fit the vectorizer to synopses\n",
    "            data.at[i, 'text'] = matrix.toarray()\n",
    "            \n",
    "    print(data.at[0, 'text']) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAESTRA DE *NUMBER* AÑOS QUE TUVO RELACIONES CON UN ALUMNO DE *NUMBER* DARÁ EDUCACIÓN SEXUAL EN EL CONALEP\n",
      "Estados Unidos.- Luego de que se revelará el caso de una maestra estadounidense de *NUMBER* años de nombre Alexandria Vera que fue acusada de abusar de uno de sus alumno de *NUMBER* años (con quien tuvo un noviazgo e incluso quedó embarazada), el juez que analizó la situación finalmente determinó que la profesora no será encarcelada pero si deberá pagar una multa de USD*NUMBER* mil dólares, alejarse del adolescente para siempre, y dar un servicio comunitario de *NUMBER* horas como profesora en un CONALEP de la Ciudad de México.\n",
      "El juez señala que el chico involucrado confesó que \"tuvo relaciones con su consentimiento\" y además sus papás aprobaban el noviazgo:\n",
      "\"Es un caso que llamó la atención de los medios internacionales porque ella tiene *NUMBER* y es muy atractiva, y él es un joven de apenas *NUMBER* años.\n",
      "Como el juez que iba a determinar el castigo sentía la presión de muchas personas que querían que metiera a la cárcel a la maestra, sin embargo tuve que ser objetivo: fue el propio joven y sus padres quienes me pidieron que la dejara en libertad.\n",
      "Además la verdad recordé que en mi etapa de secundaria yo y todos mis compañeros fantaseábamos con nuestras maestras (risas), así que pensé, ¿por qué ser tan severo si todos alguna vez tuvimos esa fantasía de chicos?.\n",
      "Decidí que Alexandria no pisará la cárcel pero como castigo tendrá que ir a un CONALEP a dar clases. Todos sabemos la fama que tiene los del CONA, así que será un reto muy fuerte para ella contenerse porque si vuelve a cometer el mismo delito esta vez no se salvará de pisar la cárcel\", confesó.\n",
      "El magistrado señala que tomó la decisión de mandarla a la prepa mexicana para ponerle una \"prueba de fuego\":\n",
      "\"La profesora dejó en claro que le gustan chavitos y en el CONA los chicos estarán más que dispuestos a darle entrada porque ella es muy guapa.\n",
      "Creo que es una prueba fuerte pero sensata para demostrar que efectivamente cambió y también ya está advertida; si ella vuelve a hacer lo mismo que con su anterior alumno esta vez no se salvará de pisar la cárcel.\n",
      "Además, independientemente de la situación por la que fue enviada (abuso de menores), el CONA es un lugar en donde debe cuidarse y estar siempre alerta porque el ambiente en cuestión de seguridad está muy pesado. Será como si la mandáramos a una cárcel de un país centroamericano, solo que será temporal y no estará encerrada para siempre\", puntualizó.\n"
     ]
    }
   ],
   "source": [
    "df = test.copy(deep = True)\n",
    "print(test.at[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maestr de *number* años que tuv relacion con un alumn de *number* dar educ sexual en el conalep estad unidos.- lueg de que se revel el cas de una maestr estadounidens de *number* años de nombr alexandri ver que fue acus de abus de uno de sus alumn de *number* años (con qui tuv un noviazg e inclus qued embarazada), el juez que analiz la situacion final determin que la profesor no ser encarcel per si deb pag una mult de usd*number* mil dolares, alej del adolescent par siempre, y dar un servici comunitari de *number* hor com profesor en un conalep de la ciud de mexico. el juez señal que el chic involucr confes que \"tuv relacion con su consentimiento\" y ademas sus papas aprob el noviazgo: \"es un cas que llam la atencion de los medi internacional porqu ella tien *number* y es muy atractiva, y el es un jov de apen *number* años. com el juez que iba a determin el castig sent la presion de much person que quer que met a la carcel a la maestra, sin embarg tuv que ser objetivo: fue el propi jov y sus padr quien me pid que la dej en libertad. ademas la verd record que en mi etap de secundari yo y tod mis compañer fantas con nuestr maestr (risas), asi que pense, ¿por que ser tan sever si tod algun vez tuv esa fantas de chicos?. decid que alexandri no pis la carcel per com castig tendr que ir a un conalep a dar clases. tod sab la fam que tien los del cona, asi que ser un ret muy fuert par ella conten porqu si vuelv a comet el mism delit esta vez no se salv de pis la carcel\", confeso. el magistr señal que tom la decision de mand a la prep mexican par pon una \"prueb de fuego\": \"la profesor dej en clar que le gust chavit y en el con los chic estaran mas que dispuest a darl entrad porqu ella es muy guapa. cre que es una prueb fuert per sensat par demostr que efect camb y tambien ya esta advertida; si ella vuelv a hac lo mism que con su anterior alumn esta vez no se salv de pis la carcel. ademas, independient de la situacion por la que fue envi (abus de menores), el con es un lug en dond deb cuid y estar siempr alert porqu el ambient en cuestion de segur esta muy pesado. ser com si la mand a una carcel de un pais centroamericano, sol que ser temporal y no estar encerr par siempre\", puntualizo.\n",
      "['maestr', 'number', 'años', 'tuv', 'relacion', 'alumn', 'number', 'dar', 'educ', 'sexual', 'conalep', 'unidos', 'lueg', 'revel', 'cas', 'maestr', 'estadounidens', 'number', 'años', 'nombr', 'alexandri', 'ver', 'acus', 'abus', 'alumn', 'number', 'años', 'qui', 'tuv', 'noviazg', 'inclus', 'qued', 'embarazada', 'juez', 'analiz', 'situacion', 'final', 'determin', 'profesor', 'ser', 'encarcel', 'per', 'si', 'deb', 'pag', 'mult', 'usd', 'number', 'mil', 'dolares', 'alej', 'adolescent', 'par', 'siempre', 'dar', 'servici', 'comunitari', 'number', 'hor', 'com', 'profesor', 'conalep', 'ciud', 'mexico', 'juez', 'señal', 'chic', 'involucr', 'confes', 'tuv', 'relacion', 'consentimiento', 'ademas', 'papas', 'aprob', 'noviazgo', 'cas', 'llam', 'atencion', 'medi', 'internacional', 'porqu', 'tien', 'number', 'atractiva', 'jov', 'apen', 'number', 'años', 'com', 'juez', 'iba', 'determin', 'castig', 'sent', 'presion', 'much', 'person', 'quer', 'met', 'carcel', 'maestra', 'embarg', 'tuv', 'ser', 'objetivo', 'propi', 'jov', 'padr', 'pid', 'dej', 'libertad', 'ademas', 'verd', 'record', 'etap', 'secundari', 'tod', 'compañer', 'fantas', 'nuestr', 'maestr', 'risas', 'asi', 'pense', 'ser', 'tan', 'sever', 'si', 'tod', 'algun', 'vez', 'tuv', 'fantas', 'chicos', 'decid', 'alexandri', 'pis', 'carcel', 'per', 'com', 'castig', 'tendr', 'ir', 'conalep', 'dar', 'clases', 'tod', 'sab', 'fam', 'tien', 'cona', 'asi', 'ser', 'ret', 'fuert', 'par', 'conten', 'porqu', 'si', 'vuelv', 'comet', 'mism', 'delit', 'vez', 'salv', 'pis', 'carcel', 'confeso', 'magistr', 'señal', 'tom', 'decision', 'mand', 'prep', 'mexican', 'par', 'pon', 'prueb', 'fuego', 'profesor', 'dej', 'clar', 'gust', 'chavit', 'chic', 'estaran', 'mas', 'dispuest', 'darl', 'entrad', 'porqu', 'guapa', 'cre', 'prueb', 'fuert', 'per', 'sensat', 'par', 'demostr', 'efect', 'camb', 'tambien', 'advertida', 'si', 'vuelv', 'hac', 'mism', 'anterior', 'alumn', 'vez', 'salv', 'pis', 'carcel', 'ademas', 'independient', 'situacion', 'envi', 'abus', 'menores', 'lug', 'dond', 'deb', 'cuid', 'siempr', 'alert', 'porqu', 'ambient', 'cuestion', 'segur', 'pesado', 'ser', 'com', 'si', 'mand', 'carcel', 'pais', 'centroamericano', 'sol', 'ser', 'temporal', 'encerr', 'par', 'siempre', 'puntualizo']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "get_matrix(df, 'BoW', 2000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "1        1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "2        1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "3        1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "4        0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "..     ...                                                ...\n",
       "290      1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "291      0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "292      1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "293      1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "294      0  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
