{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_preprocessing import get_input_share_tokenizer\n",
    "from pretrained_embedding import get_input_plus_embedding_vectors_share_tokenizer\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_length, max_length_sequence, emb_dim, transfer_learning, embedding_vectors,\n",
    "                 filters, kernel_size, dense_units, l2_kernel):\n",
    "    \n",
    "    X_input = Input(shape = (max_length_sequence, ))\n",
    "    \n",
    "    if transfer_learning:\n",
    "        embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim, weights=[embedding_vectors],\n",
    "                                trainable = False)(X_input)\n",
    "    else:\n",
    "        embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim,\n",
    "                                trainable = True)(X_input)\n",
    "    \n",
    "    X = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu',\n",
    "              kernel_regularizer = regularizers.l2(l2_kernel))(embedding_layer)\n",
    "    X = MaxPooling1D(pool_size = 2)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units = dense_units, activation = 'relu')(X)\n",
    "    X = Dense(units = 1, activation = 'sigmoid')(X)\n",
    "                          \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "                          \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_RNN(vocabulary_length, max_length_sequence, emb_dim, transfer_learning, embedding_vectors, \n",
    "                     lstm_units, l2_kernel, l2_recurrent, l2_activity, dropout):\n",
    "    \n",
    "    X_input = Input(shape = (max_length_sequence, ))\n",
    "    \n",
    "    if transfer_learning:\n",
    "        embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim, weights=[embedding_vectors],\n",
    "                                trainable = False, mask_zero = True)(X_input)\n",
    "    else:\n",
    "        embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim,\n",
    "                                trainable = True, mask_zero = True)(X_input)\n",
    "    \n",
    "    X = LSTM(units = lstm_units, return_sequences = False,\n",
    "            kernel_regularizer = regularizers.l2(l2_kernel),\n",
    "            recurrent_regularizer = regularizers.l2(l2_recurrent),\n",
    "            activity_regularizer = regularizers.l2(l2_activity))(embedding_layer)\n",
    "    \n",
    "    X = Dropout(rate = dropout)(X)\n",
    "    X = Dense(units = 1)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "                          \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "                          \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add n_samples from data_2 to data_1\n",
    "def add_data_portion(data_1, data_2, n_samples):\n",
    "    df_slice = data_2.sample(n_samples)\n",
    "    df_rest = data_2.loc[~data_2.index.isin(df_slice.index)]\n",
    "    df_extended = data_1.append(df_slice, ignore_index = True)\n",
    "    \n",
    "    df_rest.reset_index(inplace = True)\n",
    "    del(df_rest['index'])\n",
    "    df_extended.reset_index(inplace = True)\n",
    "    del(df_extended['index'])\n",
    "    \n",
    "    return df_extended, df_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51232</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "51228  The State Department told the Republican Natio...      0\n",
       "51229  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1\n",
       "51230   Anti-Trump Protesters Are Tools of the Oligar...      1\n",
       "51231  ADDIS ABABA, Ethiopia —President Obama convene...      0\n",
       "51232  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0\n",
       "\n",
       "[51233 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv('../data/Merged/english_dataset.csv')\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAE WILL INCLUDE THE WORD \"LADY\" IN THE SPANIS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The word \"haiga\", accepted by the RAE The Roya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YORDI ROSADO WILL WRITE AND DESIGN THE NEW SEP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNAM will train teachers to pass the Pisa test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alert: they intend to approve school books wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>We recover the story of Aleixandra, the 21-yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Reproaches, tension and sincerity: the meal in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>Russia quotes the Spanish ambassador for some ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>Saeed Malekpour was arrested in 2008, while vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     RAE WILL INCLUDE THE WORD \"LADY\" IN THE SPANIS...      1\n",
       "1     The word \"haiga\", accepted by the RAE The Roya...      1\n",
       "2     YORDI ROSADO WILL WRITE AND DESIGN THE NEW SEP...      1\n",
       "3     UNAM will train teachers to pass the Pisa test...      0\n",
       "4     Alert: they intend to approve school books wit...      1\n",
       "...                                                 ...    ...\n",
       "2566  We recover the story of Aleixandra, the 21-yea...      0\n",
       "2567  Reproaches, tension and sincerity: the meal in...      0\n",
       "2568  RT @ElMundoOpinion: \"PSOE, PP, Ciudadanos and ...      0\n",
       "2569  Russia quotes the Spanish ambassador for some ...      0\n",
       "2570  Saeed Malekpour was arrested in 2008, while vi...      0\n",
       "\n",
       "[2571 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_dataset = pd.read_csv('../data/Merged/spanish_t_dataset.csv')\n",
    "translated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_length = 10000\n",
    "max_length_sequence = 1500\n",
    "emb_dim = 300\n",
    "language = 'english'\n",
    "embedding_file_path = '../data/GloVe_Embedding/glove.6B.300d.txt'\n",
    "epochs = 7\n",
    "batch_size = 32\n",
    "\n",
    "slice_size = [500, 1000, 1500, 2000, 2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve with trainable embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51733, 1500) (2071, 1500)\n",
      "Epoch 1/7\n",
      "51733/51733 [==============================] - 1652s 32ms/step - loss: 0.1003 - accuracy: 0.9577\n",
      "Epoch 2/7\n",
      "51733/51733 [==============================] - 1681s 32ms/step - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 3/7\n",
      "51733/51733 [==============================] - 1714s 33ms/step - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 4/7\n",
      "51733/51733 [==============================] - 1590s 31ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 5/7\n",
      "51733/51733 [==============================] - 2109s 41ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 6/7\n",
      "51733/51733 [==============================] - 1331s 26ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 7/7\n",
      "51733/51733 [==============================] - 1121s 22ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "2071/2071 [==============================] - 10s 5ms/step\n",
      "0.611\n",
      "(52233, 1500) (1571, 1500)\n",
      "Epoch 1/7\n",
      "52233/52233 [==============================] - 1471s 28ms/step - loss: 0.1110 - accuracy: 0.9579\n",
      "Epoch 2/7\n",
      "52233/52233 [==============================] - 1370s 26ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "Epoch 3/7\n",
      "52233/52233 [==============================] - 1184s 23ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 4/7\n",
      "52233/52233 [==============================] - 1120s 21ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 5/7\n",
      "52233/52233 [==============================] - 1126s 22ms/step - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 6/7\n",
      "52233/52233 [==============================] - 1124s 22ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 7/7\n",
      "52233/52233 [==============================] - 1119s 21ms/step - loss: 0.0065 - accuracy: 0.9986\n",
      "1571/1571 [==============================] - 7s 4ms/step\n",
      "0.642\n",
      "(52733, 1500) (1071, 1500)\n",
      "Epoch 1/7\n",
      "52733/52733 [==============================] - 1129s 21ms/step - loss: 0.1060 - accuracy: 0.9607\n",
      "Epoch 2/7\n",
      "52733/52733 [==============================] - 1127s 21ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "Epoch 3/7\n",
      "52733/52733 [==============================] - 1125s 21ms/step - loss: 0.0114 - accuracy: 0.9969\n",
      "Epoch 4/7\n",
      "52733/52733 [==============================] - 1126s 21ms/step - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 5/7\n",
      "52733/52733 [==============================] - 1121s 21ms/step - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 6/7\n",
      "52733/52733 [==============================] - 1121s 21ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 7/7\n",
      "52733/52733 [==============================] - 1121s 21ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "1071/1071 [==============================] - 5s 4ms/step\n",
      "0.638\n",
      "(53233, 1500) (571, 1500)\n",
      "Epoch 1/7\n",
      "53233/53233 [==============================] - 1142s 21ms/step - loss: 0.1122 - accuracy: 0.9531\n",
      "Epoch 2/7\n",
      "53233/53233 [==============================] - 1142s 21ms/step - loss: 0.0327 - accuracy: 0.9889\n",
      "Epoch 3/7\n",
      "53233/53233 [==============================] - 1129s 21ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 4/7\n",
      "53233/53233 [==============================] - 1202s 23ms/step - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 5/7\n",
      "53233/53233 [==============================] - 1161s 22ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 6/7\n",
      "53233/53233 [==============================] - 1161s 22ms/step - loss: 0.0073 - accuracy: 0.9983\n",
      "Epoch 7/7\n",
      "53233/53233 [==============================] - 1180s 22ms/step - loss: 0.0078 - accuracy: 0.9982\n",
      "571/571 [==============================] - 2s 4ms/step\n",
      "0.648\n",
      "(53733, 1500) (71, 1500)\n",
      "Epoch 1/7\n",
      "53733/53733 [==============================] - 1161s 22ms/step - loss: 0.2776 - accuracy: 0.9426\n",
      "Epoch 2/7\n",
      "53733/53733 [==============================] - 1177s 22ms/step - loss: 0.1137 - accuracy: 0.9818\n",
      "Epoch 3/7\n",
      "53733/53733 [==============================] - 1150s 21ms/step - loss: 0.0560 - accuracy: 0.9916\n",
      "Epoch 4/7\n",
      "53733/53733 [==============================] - 1146s 21ms/step - loss: 0.0345 - accuracy: 0.9940\n",
      "Epoch 5/7\n",
      "53733/53733 [==============================] - 1149s 21ms/step - loss: 0.0257 - accuracy: 0.9951\n",
      "Epoch 6/7\n",
      "53733/53733 [==============================] - 1167s 22ms/step - loss: 0.0195 - accuracy: 0.9965\n",
      "Epoch 7/7\n",
      "53733/53733 [==============================] - 1148s 21ms/step - loss: 0.0186 - accuracy: 0.9967\n",
      "71/71 [==============================] - 0s 6ms/step\n",
      "0.732\n",
      "[0.611, 0.642, 0.638, 0.648, 0.732]\n"
     ]
    }
   ],
   "source": [
    "trainable_emb_results = []\n",
    "\n",
    "for n_samples in slice_size:\n",
    "    \n",
    "    train_dataset, test_dataset = add_data_portion(english_dataset, translated_dataset, n_samples) # add n_samples from data_2 to data_1\n",
    "    \n",
    "    X_train, X_test, df1, df2 = get_input_share_tokenizer(train_dataset, test_dataset, stemming = False, remove_stopwords = True, \n",
    "                                                          vocabulary_length = vocabulary_length, max_length_sequence = max_length_sequence, language = language)\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    model = create_model(vocabulary_length, max_length_sequence, emb_dim, transfer_learning = False, embedding_vectors = False,\n",
    "                         filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
    "    \n",
    "    Y_train = train_dataset.label.values\n",
    "    model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
    "    Y_test = test_dataset.label.values\n",
    "    loss, acc = model.evaluate(X_test, Y_test)\n",
    "    trainable_emb_results.append(round(acc, 3))\n",
    "    print(round(acc, 3))\n",
    "    \n",
    "print(trainable_emb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(slice_size, trainable_emb_results, color = 'blue', label = 'trainable_emb_results')\n",
    "plt.xlabel('n_samples')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('CNN_Learning Curve')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Fixed Embedding _ 2500 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53733, 1500) (71, 1500) (10000, 300)\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/7\n",
      "53733/53733 [==============================] - 974s 18ms/step - loss: 0.2963 - accuracy: 0.9272\n",
      "Epoch 2/7\n",
      "53733/53733 [==============================] - 896s 17ms/step - loss: 0.0861 - accuracy: 0.9662\n",
      "Epoch 3/7\n",
      "53733/53733 [==============================] - 729s 14ms/step - loss: 0.0531 - accuracy: 0.9794\n",
      "Epoch 4/7\n",
      "53733/53733 [==============================] - 714s 13ms/step - loss: 0.0337 - accuracy: 0.9872\n",
      "Epoch 5/7\n",
      "53733/53733 [==============================] - 714s 13ms/step - loss: 0.0223 - accuracy: 0.9916\n",
      "Epoch 6/7\n",
      "53733/53733 [==============================] - 724s 13ms/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 7/7\n",
      "53733/53733 [==============================] - 730s 14ms/step - loss: 0.0163 - accuracy: 0.9939\n",
      "71/71 [==============================] - 0s 6ms/step\n",
      "0.577\n"
     ]
    }
   ],
   "source": [
    "trainable_emb_results = []\n",
    "train_dataset, test_dataset = add_data_portion(english_dataset, translated_dataset, 2500) # add n_samples from data_2 to data_1\n",
    "\n",
    "X_train, X_test, embedding_vectors = get_input_plus_embedding_vectors_share_tokenizer(train_dataset, test_dataset, embedding_file_path, \n",
    "                                                                                      vocabulary_length, max_length_sequence, emb_dim, language)\n",
    "\n",
    "print(X_train.shape, X_test.shape, embedding_vectors.shape)\n",
    "\n",
    "model = create_model(vocabulary_length, max_length_sequence, emb_dim, transfer_learning = True, embedding_vectors = embedding_vectors, \n",
    "                     filters = 16, kernel_size = 10, dense_units = 4, l2_kernel = 0)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
    "\n",
    "Y_train = train_dataset.label.values\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
    "Y_test = test_dataset.label.values\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(round(acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN 2500 Samples - Trainable Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53733, 1500) (71, 1500)\n",
      "Epoch 1/7\n",
      "53733/53733 [==============================] - 2642s 49ms/step - loss: 0.2977 - accuracy: 0.9188\n",
      "Epoch 2/7\n",
      "53733/53733 [==============================] - 2466s 46ms/step - loss: 0.2052 - accuracy: 0.9289\n",
      "Epoch 3/7\n",
      "53733/53733 [==============================] - 2846s 53ms/step - loss: 0.1690 - accuracy: 0.9506\n",
      "Epoch 4/7\n",
      "53733/53733 [==============================] - 2229s 41ms/step - loss: 0.1522 - accuracy: 0.9583\n",
      "Epoch 5/7\n",
      "53733/53733 [==============================] - 2520s 47ms/step - loss: 0.1295 - accuracy: 0.9666\n",
      "Epoch 6/7\n",
      "53733/53733 [==============================] - 4201s 78ms/step - loss: 0.1181 - accuracy: 0.9685\n",
      "Epoch 7/7\n",
      "53733/53733 [==============================] - 2617s 49ms/step - loss: 0.1085 - accuracy: 0.9715\n",
      "71/71 [==============================] - 2s 25ms/step\n",
      "0.634\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = add_data_portion(english_dataset, translated_dataset, 2500) # add 2500 from data_2 to data_1\n",
    "\n",
    "X_train, X_test, df1, df2 = get_input_share_tokenizer(train_dataset, test_dataset, stemming = False, remove_stopwords = True, \n",
    "                                                      vocabulary_length = vocabulary_length, max_length_sequence = max_length_sequence, language = language)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "model = create_model_RNN(vocabulary_length, max_length_sequence, emb_dim, transfer_learning = False, embedding_vectors = False, \n",
    "                             lstm_units = 4, l2_kernel = 0.01, l2_recurrent = 0.01, l2_activity = 0, dropout = 0)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
    "\n",
    "Y_train = train_dataset.label.values\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
    "Y_test = test_dataset.label.values\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(round(acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN  2500 Samples -  Fixed Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53733, 1500) (71, 1500) (10000, 300)\n",
      "Epoch 1/7\n",
      "53733/53733 [==============================] - 1709s 32ms/step - loss: 0.3318 - accuracy: 0.8780\n",
      "Epoch 2/7\n",
      "53733/53733 [==============================] - 1685s 31ms/step - loss: 0.2259 - accuracy: 0.9159\n",
      "Epoch 3/7\n",
      "53733/53733 [==============================] - 1706s 32ms/step - loss: 0.1966 - accuracy: 0.9268\n",
      "Epoch 4/7\n",
      "53733/53733 [==============================] - 1645s 31ms/step - loss: 0.1694 - accuracy: 0.9366\n",
      "Epoch 5/7\n",
      "53733/53733 [==============================] - 1613s 30ms/step - loss: 0.1501 - accuracy: 0.9446\n",
      "Epoch 6/7\n",
      "53733/53733 [==============================] - 1682s 31ms/step - loss: 0.1626 - accuracy: 0.9415\n",
      "Epoch 7/7\n",
      "53733/53733 [==============================] - 2066s 38ms/step - loss: 0.1390 - accuracy: 0.9486\n",
      "71/71 [==============================] - 1s 19ms/step\n",
      "0.648\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = add_data_portion(english_dataset, translated_dataset, 2500) # add 2500 from data_2 to data_1\n",
    "\n",
    "X_train, X_test, embedding_vectors = get_input_plus_embedding_vectors_share_tokenizer(train_dataset, test_dataset, embedding_file_path, \n",
    "                                                                                      vocabulary_length, max_length_sequence, emb_dim, language)\n",
    "\n",
    "print(X_train.shape, X_test.shape, embedding_vectors.shape)\n",
    "\n",
    "model = create_model_RNN(vocabulary_length, max_length_sequence, emb_dim, transfer_learning = True, embedding_vectors = embedding_vectors, \n",
    "                             lstm_units = 8, l2_kernel = 0, l2_recurrent = 0, l2_activity = 0, dropout = 0.5)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
    "\n",
    "Y_train = train_dataset.label.values\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
    "Y_test = test_dataset.label.values\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
