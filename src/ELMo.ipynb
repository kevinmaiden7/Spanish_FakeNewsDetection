{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5a6emTisYeo",
        "outputId": "8773fd64-7cfe-42c1-c14f-80d918bcdfc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print (\"setting tensorflow version in colab\")\n",
        "    %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting tensorflow version in colab\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Zg2jilsfC-",
        "outputId": "4754356a-786a-4e59-d1f2-5cc1e2037b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from data_preprocessing import remove_stop_words, text_normalization\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Lambda, Dense, Activation\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers import Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyTRHmBZtquK",
        "outputId": "7068af51-b753-4c4f-ab49-ad2705e8909d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "english_dataset = pd.read_csv('small_english_dataset.csv')\n",
        "translated_dataset = pd.read_csv('spanish_t_dataset.csv')\n",
        "print(english_dataset.shape, translated_dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6335, 2) (2571, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEd5xksyjqH"
      },
      "source": [
        "def get_X(df):\n",
        "  text_normalization(df) # Normalize text\n",
        "  remove_stop_words(df, language, get_tokenize = True) # Remove stop words [and Tokenize texts]\n",
        "\n",
        "  # Padding text\n",
        "  new_X = []\n",
        "  for seq in df.text:\n",
        "      new_seq = []\n",
        "      for i in range(max_length_sequence):\n",
        "          try:\n",
        "              new_seq.append(seq[i])\n",
        "          except:\n",
        "              new_seq.append(\"PADword\")\n",
        "      new_X.append(new_seq)\n",
        "\n",
        "  return(new_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSoQcmYVtpDW"
      },
      "source": [
        "max_length_sequence = 100\n",
        "language = 'english'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VnhCSwQt-_I"
      },
      "source": [
        "X_english = get_X(english_dataset)\n",
        "X_translated = get_X(translated_dataset)\n",
        "\n",
        "Y_english = english_dataset.label.values\n",
        "Y_translated = translated_dataset.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlnsMixwu-tH",
        "outputId": "a7a850d8-af9c-44b1-afaa-4382a74d6a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(X_english), len(X_english[0]))\n",
        "print(len(X_translated), len(X_translated[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6335 100\n",
            "2571 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnStDw0HtZu0"
      },
      "source": [
        "Get ELMo from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOrv3JQzsmyu",
        "outputId": "63b86377-3d44-4f35-baa7-b41237716c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable = False)\n",
        "elmo_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_hub.module.Module at 0x7f5f1a3b2828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuctFs9i-0tR"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XV6I8tjtxfH"
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSSsYiCwBFA"
      },
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_length_sequence])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNTntyOFwHK0"
      },
      "source": [
        "def create_model_RNN(max_length_sequence, lstm_units, l2_kernel, l2_recurrent, l2_activity, dropout):\n",
        "    \n",
        "    X_input = Input(shape = (max_length_sequence, ), dtype=tf.string)\n",
        "    \n",
        "    embedding_layer = Lambda(ElmoEmbedding, output_shape = (max_length_sequence, 1024))(X_input)\n",
        "    \n",
        "    X = LSTM(units = lstm_units, return_sequences = False,\n",
        "            kernel_regularizer = regularizers.l2(l2_kernel),\n",
        "            recurrent_regularizer = regularizers.l2(l2_recurrent),\n",
        "            activity_regularizer = regularizers.l2(l2_activity))(embedding_layer)\n",
        "    \n",
        "    X = Dropout(rate = dropout)(X)\n",
        "    X = Dense(units = 1, activation = 'sigmoid')(X)\n",
        "                          \n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "                          \n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEmTHcQ4wNAp"
      },
      "source": [
        "def create_model_CNN(max_length_sequence, filters, kernel_size, dense_units, l2_kernel):\n",
        "    \n",
        "    X_input = Input(shape = (max_length_sequence, ), dtype=tf.string)\n",
        "    \n",
        "    embedding_layer = Lambda(ElmoEmbedding, output_shape = (max_length_sequence, 1024))(X_input)\n",
        "    \n",
        "    X = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu',\n",
        "              kernel_regularizer = regularizers.l2(l2_kernel))(embedding_layer)\n",
        "    X = MaxPooling1D(pool_size = 2)(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(units = dense_units, activation = 'relu')(X)\n",
        "    X = Dense(units = 1, activation = 'sigmoid')(X)\n",
        "                          \n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "                          \n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0EzM3kQuOSI"
      },
      "source": [
        "Execute Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOA7KazguYqA"
      },
      "source": [
        "Train and Validation with English Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT-DwRKcw0T4"
      },
      "source": [
        "epochs = 7\n",
        "test_size = 0.1\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_english, Y_english, test_size = test_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2EN2pbIwPKI",
        "outputId": "bd8a82a4-2173-4b4e-cd40-f147daa29b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(X_train), len(Y_train), len(X_test), len(Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5701 5701 634 634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw9_XDY27Vrd",
        "outputId": "01c75d25-a39f-4d18-acb3-cdaa670995ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fit_batch_size_train = int(len(X_train)/batch_size) * batch_size\n",
        "X_train = X_train[:fit_batch_size_train]\n",
        "Y_train = Y_train[:fit_batch_size_train]\n",
        "print(len(X_train), len(Y_train))\n",
        "\n",
        "fit_batch_size_test = int(len(X_test)/batch_size) * batch_size\n",
        "X_test = X_test[:fit_batch_size_test]\n",
        "Y_test = Y_test[:fit_batch_size_test]\n",
        "print(len(X_test), len(Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5696 5696\n",
            "608 608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJmPTrw9ul-E"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V7rMdsrw6rY",
        "outputId": "4ffd0df1-a2fd-4d82-a499-4d7579ff5443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  RNN = create_model_RNN(max_length_sequence = max_length_sequence, lstm_units = 8, l2_kernel = 0, l2_recurrent = 0, l2_activity = 0, dropout = 0.5)\n",
        "  RNN.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
        "  RNN.summary() \n",
        "  RNN.fit(np.array(X_train), Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
        "  loss, acc = RNN.evaluate(np.array(X_test), Y_test) # Evaluate model\n",
        "  print(loss, round(acc, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 8)                 33056     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 33,065\n",
            "Trainable params: 33,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "5696/5696 [==============================] - 2883s 506ms/step - loss: 0.6133 - accuracy: 0.6642\n",
            "Epoch 2/7\n",
            "5696/5696 [==============================] - 2891s 507ms/step - loss: 0.5023 - accuracy: 0.7762\n",
            "Epoch 3/7\n",
            "5696/5696 [==============================] - 2918s 512ms/step - loss: 0.4421 - accuracy: 0.8160\n",
            "Epoch 4/7\n",
            "5696/5696 [==============================] - 2918s 512ms/step - loss: 0.3683 - accuracy: 0.8587\n",
            "Epoch 5/7\n",
            "5696/5696 [==============================] - 2909s 511ms/step - loss: 0.3508 - accuracy: 0.8613\n",
            "Epoch 6/7\n",
            "5696/5696 [==============================] - 2903s 510ms/step - loss: 0.3299 - accuracy: 0.8711\n",
            "Epoch 7/7\n",
            "5696/5696 [==============================] - 2899s 509ms/step - loss: 0.3215 - accuracy: 0.8775\n",
            "608/608 [==============================] - 311s 511ms/step\n",
            "0.29496031136889206 0.887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlbcQuOpuq7K"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G0xrDUgusG5",
        "outputId": "5e1dda1b-7b55-4fe5-fe40-6ab90ae68acb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  CNN = create_model_CNN(max_length_sequence = max_length_sequence, filters = 16, kernel_size = 10, dense_units = 4, l2_kernel = 0)\n",
        "  CNN.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # Compile model\n",
        "  CNN.summary() \n",
        "  CNN.fit(np.array(X_train), Y_train, epochs = epochs, batch_size = batch_size, shuffle = True) # Fit model\n",
        "  loss, acc = CNN.evaluate(np.array(X_test), Y_test) # Evaluate model\n",
        "  print(loss, round(acc, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 91, 16)            163856    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 45, 16)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 720)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2884      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 166,745\n",
            "Trainable params: 166,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "5696/5696 [==============================] - 3262s 573ms/step - loss: 0.4295 - accuracy: 0.7900\n",
            "Epoch 2/7\n",
            "5696/5696 [==============================] - 3229s 567ms/step - loss: 0.2143 - accuracy: 0.9140\n",
            "Epoch 3/7\n",
            "5696/5696 [==============================] - 3180s 558ms/step - loss: 0.0976 - accuracy: 0.9698\n",
            "Epoch 4/7\n",
            "5696/5696 [==============================] - 3102s 545ms/step - loss: 0.0413 - accuracy: 0.9916\n",
            "Epoch 5/7\n",
            "5696/5696 [==============================] - 3064s 538ms/step - loss: 0.0187 - accuracy: 0.9968\n",
            "Epoch 6/7\n",
            "5696/5696 [==============================] - 3152s 553ms/step - loss: 0.0083 - accuracy: 0.9993\n",
            "Epoch 7/7\n",
            "5696/5696 [==============================] - 3176s 558ms/step - loss: 0.0041 - accuracy: 0.9998\n",
            "608/608 [==============================] - 342s 563ms/step\n",
            "0.35322865490850647 0.903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2lGy9GputD_"
      },
      "source": [
        "Train with English Dataset and Validation with Translated Dataset."
      ]
    }
  ]
}