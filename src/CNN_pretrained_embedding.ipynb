{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pretrained_embedding import get_input_plus_embedding_vectors\n",
    "from grid_search_three_subsets import grid_search\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors,\n",
    "                 filters, kernel_size, dense_units, l2_kernel):\n",
    "    \n",
    "    X_input = Input(shape = (max_length_sequence, ))\n",
    "    embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim, weights=[embedding_vectors],\n",
    "                                trainable = False)(X_input)\n",
    "    \n",
    "    X = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu',\n",
    "              kernel_regularizer = regularizers.l2(l2_kernel))(embedding_layer)\n",
    "    X = MaxPooling1D(pool_size = 2)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units = dense_units, activation = 'relu')(X)\n",
    "    X = Dense(units = 1, activation = 'sigmoid')(X)\n",
    "                          \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "                          \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51232</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "51228  The State Department told the Republican Natio...      0\n",
       "51229  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1\n",
       "51230   Anti-Trump Protesters Are Tools of the Oligar...      1\n",
       "51231  ADDIS ABABA, Ethiopia —President Obama convene...      0\n",
       "51232  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0\n",
       "\n",
       "[51233 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv('../data/Merged/english_dataset.csv')\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_length = 10000\n",
    "max_length_sequence = 1500\n",
    "emb_dim = 300\n",
    "language = 'english'\n",
    "embedding_file_path = '../data/GloVe_Embedding/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, df, embedding_vectors = get_input_plus_embedding_vectors(english_dataset, embedding_file_path, \n",
    "                                                           vocabulary_length, max_length_sequence, emb_dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "model_0 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 4, l2_kernel = 0)\n",
    "model_1 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 8, l2_kernel = 0)\n",
    "model_2 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0)\n",
    "model_3 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0.01)\n",
    "\n",
    "\n",
    "models.append(model_0)\n",
    "models.append(model_1)\n",
    "models.append(model_2)\n",
    "models.append(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.label.values\n",
    "epochs = 7\n",
    "batch_size = 32\n",
    "iterations = 5\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 449s 14ms/step - loss: 0.1332 - accuracy: 0.9499\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 440s 13ms/step - loss: 0.0555 - accuracy: 0.9805\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 436s 13ms/step - loss: 0.0260 - accuracy: 0.9914\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0118 - accuracy: 0.9968\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0065 - accuracy: 0.9977\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 418s 13ms/step - loss: 0.1378 - accuracy: 0.9450\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 422s 13ms/step - loss: 0.0511 - accuracy: 0.9819\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 518s 16ms/step - loss: 0.0241 - accuracy: 0.9918\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 438s 13ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 422s 13ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 418s 13ms/step - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 417s 13ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "8198/8198 [==============================] - 34s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 593s 18ms/step - loss: 0.1313 - accuracy: 0.9526\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 618s 19ms/step - loss: 0.0582 - accuracy: 0.9792\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 464s 14ms/step - loss: 0.0291 - accuracy: 0.9894\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 441s 13ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 443s 14ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 433s 13ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 480s 15ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "8198/8198 [==============================] - 41s 5ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 458s 14ms/step - loss: 0.1406 - accuracy: 0.9493\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 439s 13ms/step - loss: 0.0596 - accuracy: 0.9782\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 438s 13ms/step - loss: 0.0275 - accuracy: 0.9906\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 449s 14ms/step - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 441s 13ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 455s 14ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 440s 13ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "8198/8198 [==============================] - 39s 5ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 454s 14ms/step - loss: 0.1375 - accuracy: 0.9482\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 475s 15ms/step - loss: 0.0450 - accuracy: 0.9846\n",
      "Epoch 3/7\n",
      " 6464/32788 [====>.........................] - ETA: 9:20 - loss: 0.0182 - accuracy: 0.9949"
     ]
    }
   ],
   "source": [
    "best_model_index, test_acc = grid_search(X, Y, models, epochs, batch_size, iterations, test_size)\n",
    "print('best_model_index: ' + str(best_model_index), 'test acc: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model with English Dataset and Evaluate with Translated Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
