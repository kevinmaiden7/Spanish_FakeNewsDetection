{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pretrained_embedding import get_input_plus_embedding_vectors\n",
    "from grid_search_three_subsets import grid_search\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors,\n",
    "                 filters, kernel_size, dense_units, l2_kernel):\n",
    "    \n",
    "    X_input = Input(shape = (max_length_sequence, ))\n",
    "    embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim, weights=[embedding_vectors],\n",
    "                                trainable = False)(X_input)\n",
    "    \n",
    "    X = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu',\n",
    "              kernel_regularizer = regularizers.l2(l2_kernel))(embedding_layer)\n",
    "    X = MaxPooling1D(pool_size = 2)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units = dense_units, activation = 'relu')(X)\n",
    "    X = Dense(units = 1, activation = 'sigmoid')(X)\n",
    "                          \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "                          \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51232</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "51228  The State Department told the Republican Natio...      0\n",
       "51229  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1\n",
       "51230   Anti-Trump Protesters Are Tools of the Oligar...      1\n",
       "51231  ADDIS ABABA, Ethiopia —President Obama convene...      0\n",
       "51232  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0\n",
       "\n",
       "[51233 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv('../data/Merged/english_dataset.csv')\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_length = 10000\n",
    "max_length_sequence = 1500\n",
    "emb_dim = 300\n",
    "language = 'english'\n",
    "embedding_file_path = '../data/GloVe_Embedding/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, df, embedding_vectors = get_input_plus_embedding_vectors(english_dataset, embedding_file_path, \n",
    "                                                           vocabulary_length, max_length_sequence, emb_dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "model_0 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 4, l2_kernel = 0)\n",
    "model_1 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 8, l2_kernel = 0)\n",
    "model_2 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0)\n",
    "model_3 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, filters = 16, kernel_size = 10, dense_units = 12, l2_kernel = 0.01)\n",
    "\n",
    "\n",
    "models.append(model_0)\n",
    "models.append(model_1)\n",
    "models.append(model_2)\n",
    "models.append(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.label.values\n",
    "epochs = 7\n",
    "batch_size = 32\n",
    "iterations = 5\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 449s 14ms/step - loss: 0.1332 - accuracy: 0.9499\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 440s 13ms/step - loss: 0.0555 - accuracy: 0.9805\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 436s 13ms/step - loss: 0.0260 - accuracy: 0.9914\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0118 - accuracy: 0.9968\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 421s 13ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0065 - accuracy: 0.9977\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 418s 13ms/step - loss: 0.1378 - accuracy: 0.9450\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 422s 13ms/step - loss: 0.0511 - accuracy: 0.9819\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 518s 16ms/step - loss: 0.0241 - accuracy: 0.9918\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 438s 13ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 422s 13ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 418s 13ms/step - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 417s 13ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "8198/8198 [==============================] - 34s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 593s 18ms/step - loss: 0.1313 - accuracy: 0.9526\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 618s 19ms/step - loss: 0.0582 - accuracy: 0.9792\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 464s 14ms/step - loss: 0.0291 - accuracy: 0.9894\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 441s 13ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 443s 14ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 433s 13ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 480s 15ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "8198/8198 [==============================] - 41s 5ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 458s 14ms/step - loss: 0.1406 - accuracy: 0.9493\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 439s 13ms/step - loss: 0.0596 - accuracy: 0.9782\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 438s 13ms/step - loss: 0.0275 - accuracy: 0.9906\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 449s 14ms/step - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 441s 13ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 455s 14ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 440s 13ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "8198/8198 [==============================] - 39s 5ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 454s 14ms/step - loss: 0.1375 - accuracy: 0.9482\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 475s 15ms/step - loss: 0.0450 - accuracy: 0.9846\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 669s 20ms/step - loss: 0.0191 - accuracy: 0.9939\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 496s 15ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 468s 14ms/step - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 460s 14ms/step - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 467s 14ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "8198/8198 [==============================] - 42s 5ms/step\n",
      "Model 0 --> dev_acc: 0.974 +- 0.002\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 477s 15ms/step - loss: 0.1354 - accuracy: 0.9485\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 476s 15ms/step - loss: 0.0532 - accuracy: 0.9817\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 472s 14ms/step - loss: 0.0200 - accuracy: 0.9929\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 469s 14ms/step - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 475s 14ms/step - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 665s 20ms/step - loss: 0.0081 - accuracy: 0.9969\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 966s 29ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "8198/8198 [==============================] - 61s 7ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 568s 17ms/step - loss: 0.1451 - accuracy: 0.9427\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 608s 19ms/step - loss: 0.0604 - accuracy: 0.9797\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 553s 17ms/step - loss: 0.0293 - accuracy: 0.9915\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 546s 17ms/step - loss: 0.0148 - accuracy: 0.9949\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 508s 16ms/step - loss: 0.0077 - accuracy: 0.9973\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 500s 15ms/step - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 501s 15ms/step - loss: 0.0067 - accuracy: 0.9978\n",
      "8198/8198 [==============================] - 42s 5ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 495s 15ms/step - loss: 0.1379 - accuracy: 0.9458\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 564s 17ms/step - loss: 0.0591 - accuracy: 0.9794\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 570s 17ms/step - loss: 0.0299 - accuracy: 0.9898\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 521s 16ms/step - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 484s 15ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 482s 15ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 482s 15ms/step - loss: 0.0114 - accuracy: 0.9968\n",
      "8198/8198 [==============================] - 46s 6ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 467s 14ms/step - loss: 0.1325 - accuracy: 0.9477\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 466s 14ms/step - loss: 0.0562 - accuracy: 0.9799\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 466s 14ms/step - loss: 0.0303 - accuracy: 0.9899\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 552s 17ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 517s 16ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 494s 15ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 452s 14ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "8198/8198 [==============================] - 36s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 442s 13ms/step - loss: 0.1325 - accuracy: 0.9487\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 441s 13ms/step - loss: 0.0478 - accuracy: 0.9832\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 439s 13ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 436s 13ms/step - loss: 0.0118 - accuracy: 0.9963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 433s 13ms/step - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 438s 13ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 433s 13ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "8198/8198 [==============================] - 39s 5ms/step\n",
      "Model 1 --> dev_acc: 0.972 +- 0.003\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 476s 15ms/step - loss: 0.1293 - accuracy: 0.9481\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 592s 18ms/step - loss: 0.0508 - accuracy: 0.9827\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 531s 16ms/step - loss: 0.0216 - accuracy: 0.9923\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 528s 16ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 548s 17ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 553s 17ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 595s 18ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "8198/8198 [==============================] - 60s 7ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 625s 19ms/step - loss: 0.1367 - accuracy: 0.9461\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 556s 17ms/step - loss: 0.0504 - accuracy: 0.9827\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 554s 17ms/step - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 534s 16ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 460s 14ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 437s 13ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 430s 13ms/step - loss: 0.1341 - accuracy: 0.9482\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.0513 - accuracy: 0.9820\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 423s 13ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.1201 - accuracy: 0.9525\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.0455 - accuracy: 0.9832\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0178 - accuracy: 0.9942\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.0077 - accuracy: 0.9975\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 437s 13ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 432s 13ms/step - loss: 0.0061 - accuracy: 0.9978\n",
      "8198/8198 [==============================] - 36s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 423s 13ms/step - loss: 0.1189 - accuracy: 0.9542\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.0523 - accuracy: 0.9816\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 422s 13ms/step - loss: 0.0238 - accuracy: 0.9920\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 428s 13ms/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 461s 14ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "8198/8198 [==============================] - 34s 4ms/step\n",
      "Model 2 --> dev_acc: 0.974 +- 0.001\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 526s 16ms/step - loss: 0.2121 - accuracy: 0.9443\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 485s 15ms/step - loss: 0.1465 - accuracy: 0.9674\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 437s 13ms/step - loss: 0.1338 - accuracy: 0.9732\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 435s 13ms/step - loss: 0.1303 - accuracy: 0.9765\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 433s 13ms/step - loss: 0.1242 - accuracy: 0.9779\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.1186 - accuracy: 0.9803\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 423s 13ms/step - loss: 0.1158 - accuracy: 0.9816\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 439s 13ms/step - loss: 0.2271 - accuracy: 0.9404\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 549s 17ms/step - loss: 0.1350 - accuracy: 0.9687\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 451s 14ms/step - loss: 0.1296 - accuracy: 0.9726\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 447s 14ms/step - loss: 0.1214 - accuracy: 0.9763\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.1171 - accuracy: 0.9781\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.1140 - accuracy: 0.9798\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1127 - accuracy: 0.9814\n",
      "8198/8198 [==============================] - 34s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.2201 - accuracy: 0.9501\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1424 - accuracy: 0.9692\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1352 - accuracy: 0.9736\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1324 - accuracy: 0.9751\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1234 - accuracy: 0.9780\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1240 - accuracy: 0.9792\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 429s 13ms/step - loss: 0.1168 - accuracy: 0.9801\n",
      "8198/8198 [==============================] - 35s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.2208 - accuracy: 0.9455\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1374 - accuracy: 0.9686\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1295 - accuracy: 0.9726\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1237 - accuracy: 0.9757\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1220 - accuracy: 0.9776\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1150 - accuracy: 0.9799\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1166 - accuracy: 0.9797\n",
      "8198/8198 [==============================] - 34s 4ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.2197 - accuracy: 0.9478\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 424s 13ms/step - loss: 0.1334 - accuracy: 0.9685\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.1236 - accuracy: 0.9723\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 425s 13ms/step - loss: 0.1206 - accuracy: 0.9749\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.1185 - accuracy: 0.9762\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32788/32788 [==============================] - 427s 13ms/step - loss: 0.1108 - accuracy: 0.9793\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 426s 13ms/step - loss: 0.1115 - accuracy: 0.9793\n",
      "8198/8198 [==============================] - 36s 4ms/step\n",
      "Model 3 --> dev_acc: 0.971 +- 0.003\n",
      "Epoch 1/7\n",
      "40986/40986 [==============================] - 523s 13ms/step - loss: 0.1239 - accuracy: 0.9523\n",
      "Epoch 2/7\n",
      "40986/40986 [==============================] - 526s 13ms/step - loss: 0.0526 - accuracy: 0.9814\n",
      "Epoch 3/7\n",
      "40986/40986 [==============================] - 524s 13ms/step - loss: 0.0232 - accuracy: 0.9922\n",
      "Epoch 4/7\n",
      "40986/40986 [==============================] - 523s 13ms/step - loss: 0.0106 - accuracy: 0.9963\n",
      "Epoch 5/7\n",
      "40986/40986 [==============================] - 525s 13ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 6/7\n",
      "40986/40986 [==============================] - 523s 13ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 7/7\n",
      "40986/40986 [==============================] - 523s 13ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "best_model_index: 0 test acc: 0.973\n"
     ]
    }
   ],
   "source": [
    "best_model_index, test_acc = grid_search(X, Y, models, epochs, batch_size, iterations, test_size)\n",
    "print('best_model_index: ' + str(best_model_index), 'test acc: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model with English Dataset and Evaluate with Translated Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
