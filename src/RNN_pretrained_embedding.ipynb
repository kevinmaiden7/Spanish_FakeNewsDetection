{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pretrained_embedding import get_input_plus_embedding_vectors\n",
    "from grid_search_three_subsets import grid_search\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Bidirectional, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, lstm_units, \n",
    "                 l2_kernel, l2_recurrent, l2_activity, dropout):\n",
    "    \n",
    "    X_input = Input(shape = (max_length_sequence, ))\n",
    "    embedding_layer = Embedding(input_dim = vocabulary_length, output_dim = emb_dim, weights=[embedding_vectors],\n",
    "                                trainable = False, mask_zero = True)(X_input)\n",
    "    \n",
    "    X = LSTM(units = lstm_units, return_sequences = False,\n",
    "            kernel_regularizer = regularizers.l2(l2_kernel),\n",
    "            recurrent_regularizer = regularizers.l2(l2_recurrent),\n",
    "            activity_regularizer = regularizers.l2(l2_activity))(embedding_layer)\n",
    "    \n",
    "    X = Dropout(rate = dropout)(X)\n",
    "    X = Dense(units = 1)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "                          \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "                          \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51232</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "51228  The State Department told the Republican Natio...      0\n",
       "51229  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1\n",
       "51230   Anti-Trump Protesters Are Tools of the Oligar...      1\n",
       "51231  ADDIS ABABA, Ethiopia —President Obama convene...      0\n",
       "51232  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0\n",
       "\n",
       "[51233 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = pd.read_csv('../data/Merged/english_dataset.csv')\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_length = 10000\n",
    "max_length_sequence = 1500\n",
    "emb_dim = 300\n",
    "language = 'english'\n",
    "embedding_file_path = '../data/GloVe_Embedding/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, df, embedding_vectors = get_input_plus_embedding_vectors(english_dataset, embedding_file_path, \n",
    "                                                           vocabulary_length, max_length_sequence, emb_dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1500, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,009,897\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, 8, 0.01, 0.01, 0, 0.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "model_0 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, lstm_units = 2, l2_kernel = 0.01, l2_recurrent = 0.01, l2_activity = 0, dropout = 0)\n",
    "model_1 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, lstm_units = 4, l2_kernel = 0.01, l2_recurrent = 0.01, l2_activity = 0, dropout = 0)\n",
    "model_2 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, lstm_units = 8, l2_kernel = 0.1, l2_recurrent = 0.1, l2_activity = 0, dropout = 0)\n",
    "model_3 = create_model(vocabulary_length, max_length_sequence, emb_dim, embedding_vectors, lstm_units = 8, l2_kernel = 0, l2_recurrent = 0, l2_activity = 0, dropout = 0.5)\n",
    "\n",
    "models.append(model_0)\n",
    "models.append(model_1)\n",
    "models.append(model_2)\n",
    "models.append(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.label.values\n",
    "epochs = 7\n",
    "batch_size = 32\n",
    "iterations = 5\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1159s 35ms/step - loss: 0.4413 - accuracy: 0.8723\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1084s 33ms/step - loss: 0.3854 - accuracy: 0.8839\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 992s 30ms/step - loss: 0.3151 - accuracy: 0.9060\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.3624 - accuracy: 0.8860\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 952s 29ms/step - loss: 0.3250 - accuracy: 0.9083\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 955s 29ms/step - loss: 0.2947 - accuracy: 0.9119\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1116s 34ms/step - loss: 0.2569 - accuracy: 0.9218\n",
      "8198/8198 [==============================] - 124s 15ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1221s 37ms/step - loss: 0.4817 - accuracy: 0.8489\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1222s 37ms/step - loss: 0.3336 - accuracy: 0.9004\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1037s 32ms/step - loss: 0.3595 - accuracy: 0.8858\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 1167s 36ms/step - loss: 0.2953 - accuracy: 0.9153\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 968s 30ms/step - loss: 0.2519 - accuracy: 0.9245\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 955s 29ms/step - loss: 0.3113 - accuracy: 0.8970\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 952s 29ms/step - loss: 0.2764 - accuracy: 0.9149\n",
      "8198/8198 [==============================] - 80s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1028s 31ms/step - loss: 0.4775 - accuracy: 0.8479\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 956s 29ms/step - loss: 0.3281 - accuracy: 0.9040\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 957s 29ms/step - loss: 0.3156 - accuracy: 0.9108\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 961s 29ms/step - loss: 0.2833 - accuracy: 0.9136\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.3124 - accuracy: 0.8943\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 959s 29ms/step - loss: 0.2486 - accuracy: 0.9227\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 961s 29ms/step - loss: 0.2233 - accuracy: 0.9307\n",
      "8198/8198 [==============================] - 79s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 957s 29ms/step - loss: 0.4530 - accuracy: 0.8571\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 959s 29ms/step - loss: 0.3316 - accuracy: 0.9033\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1209s 37ms/step - loss: 0.2881 - accuracy: 0.9167\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 999s 30ms/step - loss: 0.4166 - accuracy: 0.8513\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 959s 29ms/step - loss: 0.3380 - accuracy: 0.8906\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.2956 - accuracy: 0.9076\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 959s 29ms/step - loss: 0.2882 - accuracy: 0.9098\n",
      "8198/8198 [==============================] - 80s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 959s 29ms/step - loss: 0.5073 - accuracy: 0.8381\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1065s 32ms/step - loss: 0.3501 - accuracy: 0.8937\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1087s 33ms/step - loss: 0.3783 - accuracy: 0.8709\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 986s 30ms/step - loss: 0.2854 - accuracy: 0.9154\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.2563 - accuracy: 0.9247\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2560 - accuracy: 0.9244\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.2414 - accuracy: 0.9259\n",
      "8198/8198 [==============================] - 79s 10ms/step\n",
      "Model 0 --> dev_acc: 0.927 +- 0.008\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 952s 29ms/step - loss: 0.4294 - accuracy: 0.8745\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 970s 30ms/step - loss: 0.3295 - accuracy: 0.9106\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.3057 - accuracy: 0.9148\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2822 - accuracy: 0.9208\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2673 - accuracy: 0.9231\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2324 - accuracy: 0.9336\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2554 - accuracy: 0.9233\n",
      "8198/8198 [==============================] - 84s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.5941 - accuracy: 0.8171\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.4085 - accuracy: 0.8894\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 961s 29ms/step - loss: 0.3524 - accuracy: 0.9086\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.3507 - accuracy: 0.9052\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.5689 - accuracy: 0.8106\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.4056 - accuracy: 0.8936\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 960s 29ms/step - loss: 0.3165 - accuracy: 0.9162\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.6953 - accuracy: 0.7729\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.4304 - accuracy: 0.8747\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.3319 - accuracy: 0.9036\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 961s 29ms/step - loss: 0.3023 - accuracy: 0.9115\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 964s 29ms/step - loss: 0.3224 - accuracy: 0.9044\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 960s 29ms/step - loss: 0.2485 - accuracy: 0.9274\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.2132 - accuracy: 0.9382\n",
      "8198/8198 [==============================] - 84s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.4895 - accuracy: 0.8474\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2889 - accuracy: 0.9127\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.2601 - accuracy: 0.9195\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.3333 - accuracy: 0.8966\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.3215 - accuracy: 0.9067\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 985s 30ms/step - loss: 0.3673 - accuracy: 0.8822\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1054s 32ms/step - loss: 0.3176 - accuracy: 0.9155\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.6414 - accuracy: 0.8291\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 963s 29ms/step - loss: 0.4538 - accuracy: 0.8821\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 964s 29ms/step - loss: 0.3783 - accuracy: 0.8988\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 968s 30ms/step - loss: 0.3475 - accuracy: 0.9055\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 1097s 33ms/step - loss: 0.3295 - accuracy: 0.9090\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1031s 31ms/step - loss: 0.2864 - accuracy: 0.9281\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 989s 30ms/step - loss: 0.2880 - accuracy: 0.9257\n",
      "8198/8198 [==============================] - 82s 10ms/step\n",
      "Model 1 --> dev_acc: 0.935 +- 0.006\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32788/32788 [==============================] - 1008s 31ms/step - loss: 0.7675 - accuracy: 0.8620\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 973s 30ms/step - loss: 0.3825 - accuracy: 0.8874\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 977s 30ms/step - loss: 0.4801 - accuracy: 0.8696\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 984s 30ms/step - loss: 0.4245 - accuracy: 0.8733\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 981s 30ms/step - loss: 0.3840 - accuracy: 0.8761\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1103s 34ms/step - loss: 0.4159 - accuracy: 0.8776\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1054s 32ms/step - loss: 0.3845 - accuracy: 0.8808\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 983s 30ms/step - loss: 1.2640 - accuracy: 0.7818\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 983s 30ms/step - loss: 0.5453 - accuracy: 0.8685\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 994s 30ms/step - loss: 0.4319 - accuracy: 0.8779\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 1067s 33ms/step - loss: 0.4281 - accuracy: 0.8736\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 1268s 39ms/step - loss: 0.4468 - accuracy: 0.8774\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1027s 31ms/step - loss: 0.4045 - accuracy: 0.8814\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1052s 32ms/step - loss: 0.4011 - accuracy: 0.8812\n",
      "8198/8198 [==============================] - 88s 11ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1063s 32ms/step - loss: 1.0208 - accuracy: 0.8187\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1094s 33ms/step - loss: 0.4891 - accuracy: 0.8590\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1110s 34ms/step - loss: 0.4097 - accuracy: 0.8767\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 1188s 36ms/step - loss: 0.3925 - accuracy: 0.8814\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 1212s 37ms/step - loss: 0.3675 - accuracy: 0.8839\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1134s 35ms/step - loss: 0.4236 - accuracy: 0.8740\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1138s 35ms/step - loss: 0.4181 - accuracy: 0.8775\n",
      "8198/8198 [==============================] - 96s 12ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1302s 40ms/step - loss: 1.0759 - accuracy: 0.8282\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1228s 37ms/step - loss: 0.4708 - accuracy: 0.8764\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1253s 38ms/step - loss: 0.4332 - accuracy: 0.8756\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 1087s 33ms/step - loss: 0.3578 - accuracy: 0.8977\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 1181s 36ms/step - loss: 0.5669 - accuracy: 0.8561\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1143s 35ms/step - loss: 0.4743 - accuracy: 0.8794\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1122s 34ms/step - loss: 0.4765 - accuracy: 0.8726\n",
      "8198/8198 [==============================] - 96s 12ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 1008s 31ms/step - loss: 1.2356 - accuracy: 0.8149\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 988s 30ms/step - loss: 0.5837 - accuracy: 0.8686\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 990s 30ms/step - loss: 1.0079 - accuracy: 0.7591\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 991s 30ms/step - loss: 0.7467 - accuracy: 0.8382\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 987s 30ms/step - loss: 0.5427 - accuracy: 0.8790\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 988s 30ms/step - loss: 0.5479 - accuracy: 0.8593\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 986s 30ms/step - loss: 0.4245 - accuracy: 0.8927\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Model 2 --> dev_acc: 0.866 +- 0.03\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.3323 - accuracy: 0.8749\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 961s 29ms/step - loss: 0.2552 - accuracy: 0.9058\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.1874 - accuracy: 0.9387\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 957s 29ms/step - loss: 0.1518 - accuracy: 0.9501\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.1289 - accuracy: 0.9586\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 958s 29ms/step - loss: 0.1161 - accuracy: 0.9637\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 960s 29ms/step - loss: 0.1299 - accuracy: 0.9599\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 962s 29ms/step - loss: 0.4028 - accuracy: 0.8275\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 1018s 31ms/step - loss: 0.3240 - accuracy: 0.8674\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 1132s 35ms/step - loss: 0.2374 - accuracy: 0.9166\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 1150s 35ms/step - loss: 0.1890 - accuracy: 0.9358\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 1224s 37ms/step - loss: 0.2018 - accuracy: 0.9260\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 1017s 31ms/step - loss: 0.1730 - accuracy: 0.9436\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 1045s 32ms/step - loss: 0.1293 - accuracy: 0.9585\n",
      "8198/8198 [==============================] - 85s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 999s 30ms/step - loss: 0.3704 - accuracy: 0.8519\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 975s 30ms/step - loss: 0.2671 - accuracy: 0.9052\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 971s 30ms/step - loss: 0.2140 - accuracy: 0.9288\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 970s 30ms/step - loss: 0.2000 - accuracy: 0.9302\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 969s 30ms/step - loss: 0.1732 - accuracy: 0.9409\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.1429 - accuracy: 0.9533\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 970s 30ms/step - loss: 0.1307 - accuracy: 0.9602\n",
      "8198/8198 [==============================] - 87s 11ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.3932 - accuracy: 0.8347\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 971s 30ms/step - loss: 0.2802 - accuracy: 0.8962\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.3173 - accuracy: 0.8603\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.2326 - accuracy: 0.9118\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.2089 - accuracy: 0.9270\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 972s 30ms/step - loss: 0.2062 - accuracy: 0.9328\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 971s 30ms/step - loss: 0.1829 - accuracy: 0.9435\n",
      "8198/8198 [==============================] - 86s 10ms/step\n",
      "Epoch 1/7\n",
      "32788/32788 [==============================] - 975s 30ms/step - loss: 0.4047 - accuracy: 0.8271\n",
      "Epoch 2/7\n",
      "32788/32788 [==============================] - 974s 30ms/step - loss: 0.2845 - accuracy: 0.8951\n",
      "Epoch 3/7\n",
      "32788/32788 [==============================] - 974s 30ms/step - loss: 0.2509 - accuracy: 0.9111\n",
      "Epoch 4/7\n",
      "32788/32788 [==============================] - 971s 30ms/step - loss: 0.2172 - accuracy: 0.9303\n",
      "Epoch 5/7\n",
      "32788/32788 [==============================] - 974s 30ms/step - loss: 0.2013 - accuracy: 0.9291\n",
      "Epoch 6/7\n",
      "32788/32788 [==============================] - 969s 30ms/step - loss: 0.1726 - accuracy: 0.9426\n",
      "Epoch 7/7\n",
      "32788/32788 [==============================] - 965s 29ms/step - loss: 0.1477 - accuracy: 0.9504\n",
      "8198/8198 [==============================] - 86s 10ms/step\n",
      "Model 3 --> dev_acc: 0.962 +- 0.006\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40986/40986 [==============================] - 1215s 30ms/step - loss: 0.3061 - accuracy: 0.8896\n",
      "Epoch 2/7\n",
      "40986/40986 [==============================] - 1217s 30ms/step - loss: 0.2224 - accuracy: 0.9192\n",
      "Epoch 3/7\n",
      "40986/40986 [==============================] - 1281s 31ms/step - loss: 0.1623 - accuracy: 0.9440\n",
      "Epoch 4/7\n",
      "40986/40986 [==============================] - 1226s 30ms/step - loss: 0.1495 - accuracy: 0.9514\n",
      "Epoch 5/7\n",
      "40986/40986 [==============================] - 1218s 30ms/step - loss: 0.1400 - accuracy: 0.9549\n",
      "Epoch 6/7\n",
      "40986/40986 [==============================] - 1212s 30ms/step - loss: 0.1186 - accuracy: 0.9628\n",
      "Epoch 7/7\n",
      "40986/40986 [==============================] - 1219s 30ms/step - loss: 0.1140 - accuracy: 0.9665\n",
      "best_model_index: 3 test acc: 0.924\n"
     ]
    }
   ],
   "source": [
    "best_model_index, test_acc = grid_search(X, Y, models, epochs, batch_size, iterations, test_size)\n",
    "print('best_model_index: ' + str(best_model_index), 'test acc: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model with English Dataset and Evaluate with Translated Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
